use tpcds_orc_hive_5000;
set hive.map.aggr=true;
set hive.vectorized.execution.enabled=true;
set hive.auto.convert.join=true;
set hive.auto.convert.join.noconditionaltask=true;
set hive.limit.optimize.enable=true;
##
#set hive.exec.parallel=true;
#set mapreduce.map.output.compress=true;
#set mapreduce.map.output.compress=true;
#set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;
#set hive.cbo.enable=true;
#set hive.exec.compress.intermediate=true;
#set mapreduce.reduce.memory.mb=4096;
#set mapreduce.reduce.memory.mb=5120;
#set mapreduce.reduce.cpu.vcores=1;
#set mapreduce.map.memory.mb=3072;
#set mapreduce.map.memory.mb=5120;
#set mapreduce.map.cpu.vcores=1;
#set mapreduce.input.fileinputformat.split.maxsize=1433600000;
#set mapreduce.input.fileinputformat.split.maxsize=640000000;
set hive.exec.reducers.max=20;
#set mapred.reduce.slowstart.completed.maps=0.8;
set hive.tez.container.size=10240;
#set tez.runtime.io.sort.mb=100;
set tez.runtime.io.sort.mb=256;
#set hive.merge.tezfiles=true;
set hive.tez.java.opts=-Xshare:on -XX:+UseAppCDS -XX:SharedArchiveFile=/home/test/hive.jsa -XX:+UseG1GC;
set hive.tez.java.opts=-Xshare:dump -XX:+UseAppCDS -XX:SharedClassListFile=/home/test/hive.lst -XX:SharedArchiveFile=/home/test/hive.jsa -XX:+UseG1GC;
#set hive.merge.tezfiles=true;
#set hive.stats.fetch.column.stats=true;
#set hive.merge.mapredfiles = true;
#set hive.exec.compress.intermediate=true;
#set hive.strict.checks.bucketing=true;
#set mapreduce.map.output.compress=true;

set hive.tez.java.opts=-Xshare:dump -XX:+UseAppCDS -XX:SharedClassListFile=/home/test/hive.lst -XX:SharedArchiveFile=/home/test/hive.jsa -XX:+UseG1GC;
set hive.tez.java.opts=-Xshare:on -XX:+UseAppCDS -XX:SharedArchiveFile=/home/test/hive.jsa -XX:+UseG1GC;
set hive.tez.java.opts=-Xshare:off -XX:+UseAppCDS -XX:DumpLoadedClassList=/home/test/hive.lst;
